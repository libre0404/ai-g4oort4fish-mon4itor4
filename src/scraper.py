"""
é—²é±¼çˆ¬è™«æ ¸å¿ƒæ‰§è¡Œæ¨¡å—
ä¼˜åŒ–ç‰ˆæœ¬ - é›†æˆ DelayConfigã€UserAgentManagerã€IPBlockerDetector
é€‚é…å†…å®¹åˆ›ä½œè€…çš„äºŒæ‰‹è®¾å¤‡é‡‡è´­åœºæ™¯
"""

import asyncio
import json
import os
import random
from datetime import datetime
from urllib.parse import urlencode

from playwright.async_api import (
    Response,
    TimeoutError as PlaywrightTimeoutError,
    async_playwright,
)
from .stealth_helper import StealthManager

from src.ai_handler import (
    download_all_images,
    get_ai_analysis,
    send_ntfy_notification,
    cleanup_task_images,
)
from src.config import (
    AI_DEBUG_MODE,
    API_URL_PATTERN,
    DETAIL_API_URL_PATTERN,
    LOGIN_IS_EDGE,
    RUN_HEADLESS,
    RUNNING_IN_DOCKER,
    STATE_FILE,
    SKIP_AI_ANALYSIS,
)
from src.parsers import (
    _parse_search_results_json,
    _parse_user_items_data,
    calculate_reputation_from_ratings,
    parse_ratings_data,
    parse_user_head_data,
)
from src.utils import (
    format_registration_days,
    get_link_unique_key,
    random_sleep,
    safe_get,
    save_to_jsonl,
    log_time,
)
from src.optimization import DelayConfig, UserAgentManager, IPBlockerDetector
from src.config import get_random_user_agent


async def scrape_user_profile(context, user_id: str) -> dict:
    """
    é‡‡é›†é—²é±¼ç”¨æˆ·çš„å®Œæ•´ä¿¡æ¯
    
    Args:
        context: Playwright æµè§ˆå™¨ä¸Šä¸‹æ–‡
        user_id: ç”¨æˆ·ID
        
    Returns:
        dict: åŒ…å«ç”¨æˆ·ä¿¡æ¯çš„å­—å…¸
    """
    print(f"   -> å¼€å§‹é‡‡é›†ç”¨æˆ·ID: {user_id} çš„å®Œæ•´ä¿¡æ¯...")
    profile_data = {}

    # ä½¿ç”¨ Stealth é…ç½®åˆ›å»ºé¡µé¢
    page = await context.new_page(**StealthManager.get_context_config())
    await StealthManager.apply_stealth_async(page)

    # ä¸ºå„é¡¹å¼‚æ­¥ä»»åŠ¡å‡†å¤‡Futureå’Œæ•°æ®å®¹å™¨
    head_api_future = asyncio.get_event_loop().create_future()

    all_items, all_ratings = [], []
    stop_item_scrolling, stop_rating_scrolling = asyncio.Event(), asyncio.Event()

    async def handle_response(response: Response):
        """å¤„ç†APIå“åº”çš„å›è°ƒå‡½æ•°"""
        # æ•è·å¤´éƒ¨æ‘˜è¦API
        if "mtop.idle.web.user.page.head" in response.url and not head_api_future.done():
            try:
                head_api_future.set_result(await response.json())
                print(f"      [APIæ•è·] ç”¨æˆ·å¤´éƒ¨ä¿¡æ¯... æˆåŠŸ")
            except Exception as e:
                if not head_api_future.done():
                    head_api_future.set_exception(e)

        # æ•è·å•†å“åˆ—è¡¨API
        elif "mtop.idle.web.xyh.item.list" in response.url:
            try:
                data = await response.json()
                all_items.extend(data.get('data', {}).get('cardList', []))
                print(f"      [APIæ•è·] å•†å“åˆ—è¡¨... å½“å‰å·²æ•è· {len(all_items)} ä»¶")
                if not data.get('data', {}).get('nextPage', True):
                    stop_item_scrolling.set()
            except Exception as e:
                stop_item_scrolling.set()

        # æ•è·è¯„ä»·åˆ—è¡¨API
        elif "mtop.idle.web.trade.rate.list" in response.url:
            try:
                data = await response.json()
                all_ratings.extend(data.get('data', {}).get('cardList', []))
                print(f"      [APIæ•è·] è¯„ä»·åˆ—è¡¨... å½“å‰å·²æ•è· {len(all_ratings)} æ¡")
                if not data.get('data', {}).get('nextPage', True):
                    stop_rating_scrolling.set()
            except Exception as e:
                stop_rating_scrolling.set()

    page.on("response", handle_response)

    try:
        # --- ä»»åŠ¡1: å¯¼èˆªå¹¶é‡‡é›†å¤´éƒ¨ä¿¡æ¯ ---
        await page.goto(
            f"https://www.goofish.com/personal?userId={user_id}",
            wait_until="domcontentloaded",
            timeout=20000,
        )
        head_data = await asyncio.wait_for(head_api_future, timeout=15)
        profile_data = await parse_user_head_data(head_data)

        # --- ä»»åŠ¡2: æ»šåŠ¨åŠ è½½æ‰€æœ‰å•†å“ (é»˜è®¤é¡µé¢) ---
        print("      [é‡‡é›†é˜¶æ®µ] å¼€å§‹é‡‡é›†è¯¥ç”¨æˆ·çš„å•†å“åˆ—è¡¨...")
        await DelayConfig.smart_delay("api_wait")  # ç­‰å¾…ç¬¬ä¸€é¡µå•†å“APIå®Œæˆ
        
        while not stop_item_scrolling.is_set():
            await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
            try:
                await asyncio.wait_for(stop_item_scrolling.wait(), timeout=8)
            except asyncio.TimeoutError:
                print("      [æ»šåŠ¨è¶…æ—¶] å•†å“åˆ—è¡¨å¯èƒ½å·²åŠ è½½å®Œæ¯•ã€‚")
                break
        
        profile_data["å–å®¶å‘å¸ƒçš„å•†å“åˆ—è¡¨"] = await _parse_user_items_data(all_items)

        # --- ä»»åŠ¡3: ç‚¹å‡»å¹¶é‡‡é›†æ‰€æœ‰è¯„ä»· ---
        print("      [é‡‡é›†é˜¶æ®µ] å¼€å§‹é‡‡é›†è¯¥ç”¨æˆ·çš„è¯„ä»·åˆ—è¡¨...")
        rating_tab_locator = page.locator("//div[text()='ä¿¡ç”¨åŠè¯„ä»·']/ancestor::li")
        if await rating_tab_locator.count() > 0:
            await rating_tab_locator.click()
            await DelayConfig.smart_delay("api_wait")  # ç­‰å¾…ç¬¬ä¸€é¡µè¯„ä»·APIå®Œæˆ

            while not stop_rating_scrolling.is_set():
                await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                try:
                    await asyncio.wait_for(stop_rating_scrolling.wait(), timeout=8)
                except asyncio.TimeoutError:
                    print("      [æ»šåŠ¨è¶…æ—¶] è¯„ä»·åˆ—è¡¨å¯èƒ½å·²åŠ è½½å®Œæ¯•ã€‚")
                    break

            profile_data['å–å®¶æ”¶åˆ°çš„è¯„ä»·åˆ—è¡¨'] = await parse_ratings_data(all_ratings)
            reputation_stats = await calculate_reputation_from_ratings(all_ratings)
            profile_data.update(reputation_stats)
        else:
            print("      [è­¦å‘Š] æœªæ‰¾åˆ°è¯„ä»·é€‰é¡¹å¡ï¼Œè·³è¿‡è¯„ä»·é‡‡é›†ã€‚")

    except Exception as e:
        print(f"   [é”™è¯¯] é‡‡é›†ç”¨æˆ· {user_id} ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        page.remove_listener("response", handle_response)
        await page.close()
        print(f"   -> ç”¨æˆ· {user_id} ä¿¡æ¯é‡‡é›†å®Œæˆã€‚")

    return profile_data


async def scrape_xianyu(task_config: dict, debug_limit: int = 0):
    """
    ã€æ ¸å¿ƒæ‰§è¡Œå™¨ã€‘
    æ ¹æ®å•ä¸ªä»»åŠ¡é…ç½®ï¼Œå¼‚æ­¥çˆ¬å–é—²é±¼å•†å“æ•°æ®ï¼Œå¹¶å¯¹æ¯ä¸ªæ–°å‘ç°çš„å•†å“è¿›è¡Œå®æ—¶çš„ã€ç‹¬ç«‹çš„AIåˆ†æå’Œé€šçŸ¥ã€‚
    
    Args:
        task_config: ä»»åŠ¡é…ç½®å­—å…¸
        debug_limit: è°ƒè¯•æ¨¡å¼ä¸‹çš„å•†å“æ•°é‡é™åˆ¶ï¼ˆ0è¡¨ç¤ºæ— é™åˆ¶ï¼‰
        
    Returns:
        int: å¤„ç†çš„å•†å“æ•°é‡
    """
    keyword = task_config['keyword']
    max_pages = task_config.get('max_pages', 1)
    personal_only = task_config.get('personal_only', False)
    min_price = task_config.get('min_price')
    max_price = task_config.get('max_price')
    ai_prompt_text = task_config.get('ai_prompt_text', '')

    processed_item_count = 0
    stop_scraping = False

    # ã€ä¼˜åŒ–ã€‘åˆå§‹åŒ–åçˆ¬è™«æ£€æµ‹å™¨
    ip_detector = IPBlockerDetector(max_consecutive_fails=3)
    
    # åŠ è½½å†å²è®°å½•ä»¥å»é‡
    processed_links = set()
    output_filename = os.path.join("jsonl", f"{keyword.replace(' ', '_')}_full_data.jsonl")
    
    if os.path.exists(output_filename):
        print(f"LOG: å‘ç°å·²å­˜åœ¨æ–‡ä»¶ {output_filename}ï¼Œæ­£åœ¨åŠ è½½å†å²è®°å½•ä»¥å»é‡...")
        try:
            with open(output_filename, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        record = json.loads(line)
                        link = record.get('å•†å“ä¿¡æ¯', {}).get('å•†å“é“¾æ¥', '')
                        if link:
                            processed_links.add(get_link_unique_key(link))
                    except json.JSONDecodeError:
                        print(f"   [è­¦å‘Š] æ–‡ä»¶ä¸­æœ‰ä¸€è¡Œæ— æ³•è§£æä¸ºJSONï¼Œå·²è·³è¿‡ã€‚")
            print(f"LOG: åŠ è½½å®Œæˆï¼Œå·²è®°å½• {len(processed_links)} ä¸ªå·²å¤„ç†è¿‡çš„å•†å“ã€‚")
        except IOError as e:
            print(f"   [è­¦å‘Š] è¯»å–å†å²æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    else:
        print(f"LOG: è¾“å‡ºæ–‡ä»¶ {output_filename} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶ã€‚")

    async with async_playwright() as p:
        # æ ¹æ®é…ç½®å¯åŠ¨ä¸åŒçš„æµè§ˆå™¨
        if LOGIN_IS_EDGE:
            browser = await p.chromium.launch(
                headless=RUN_HEADLESS,
                channel="msedge",
                **StealthManager.get_launch_config(headless=RUN_HEADLESS),
            )
        else:
            if RUNNING_IN_DOCKER:
                browser = await p.chromium.launch(
                    headless=RUN_HEADLESS,
                    **StealthManager.get_launch_config(headless=RUN_HEADLESS),
                )
            else:
                browser = await p.chromium.launch(
                    headless=RUN_HEADLESS,
                    channel="chrome",
                    **StealthManager.get_launch_config(headless=RUN_HEADLESS),
                )

        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼Œé›†æˆ Stealth å’Œéšæœº UA
        random_ua = get_random_user_agent()
        print(f"ğŸ”„ ä½¿ç”¨User-Agent: {random_ua[:80]}...")

        context = await browser.new_context(
            storage_state=STATE_FILE,
            user_agent=random_ua,
            **StealthManager.get_context_config(),
        )

        # åˆ›å»ºä¸»é¡µé¢
        page = await context.new_page(**StealthManager.get_context_config())
        await StealthManager.apply_stealth_async(page)

        try:
            log_time("æ­¥éª¤ 1 - ç›´æ¥å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µ...")
            
            # æ„å»ºæœç´¢URL
            params = {'q': keyword}
            search_url = f"https://www.goofish.com/search?{urlencode(params)}"
            log_time(f"ç›®æ ‡URL: {search_url}")

            # å¯¼èˆªå¹¶æ•è·åˆå§‹æœç´¢APIæ•°æ®
            async with page.expect_response(
                lambda r: API_URL_PATTERN in r.url, 
                timeout=30000
            ) as response_info:
                await page.goto(search_url, wait_until="domcontentloaded", timeout=60000)

            initial_response = await response_info.value

            # ç­‰å¾…é¡µé¢åŠ è½½å‡ºå…³é”®ç­›é€‰å…ƒç´ 
            await page.wait_for_selector('text=æ–°å‘å¸ƒ', timeout=15000)

            # --- æ£€æŸ¥æ˜¯å¦å­˜åœ¨éªŒè¯å¼¹çª— ---
            baxia_dialog = page.locator("div.baxia-dialog-mask")
            middleware_widget = page.locator("div.J_MIDDLEWARE_FRAME_WIDGET")
            
            is_blocked = False
            
            try:
                await baxia_dialog.wait_for(state='visible', timeout=2000)
                is_blocked = True
                print("\n" + "="*60)
                print("ã€åçˆ¬è™«æ£€æµ‹ã€‘æ£€æµ‹åˆ° baxia-dialog éªŒè¯å¼¹çª—")
                print("="*60)
                await ip_detector.handle_blocked()
                print("å»ºè®®ï¼š")
                print("1. åœæ­¢è„šæœ¬ä¸€æ®µæ—¶é—´å†è¯•")
                print("2. è®¾ç½® RUN_HEADLESS=false ä½¿ç”¨éæ— å¤´æ¨¡å¼")
                print("3. æ£€æŸ¥ä»£ç†è®¾ç½®æˆ–æ›´æ¢IP")
                print(f"ä»»åŠ¡ '{keyword}' å°†åœ¨æ­¤å¤„ä¸­æ­¢")
                print("="*60 + "\n")
            except PlaywrightTimeoutError:
                pass

            if not is_blocked:
                try:
                    await middleware_widget.wait_for(state='visible', timeout=2000)
                    is_blocked = True
                    print("\n" + "="*60)
                    print("ã€åçˆ¬è™«æ£€æµ‹ã€‘æ£€æµ‹åˆ° J_MIDDLEWARE_FRAME_WIDGET éªŒè¯å¼¹çª—")
                    print("="*60)
                    await ip_detector.handle_blocked()
                    print("å»ºè®®ï¼š")
                    print("1. åœæ­¢è„šæœ¬ä¸€æ®µæ—¶é—´å†è¯•")
                    print("2. æ›´æ–°ç™»å½•çŠ¶æ€æ–‡ä»¶")
                    print("3. é™ä½ä»»åŠ¡æ‰§è¡Œé¢‘ç‡")
                    print(f"ä»»åŠ¡ '{keyword}' å°†åœ¨æ­¤å¤„ä¸­æ­¢")
                    print("="*60 + "\n")
                except PlaywrightTimeoutError:
                    # æœªæ£€æµ‹åˆ°å°ç¦ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                    ip_detector.reset_fails()
                    pass

            if is_blocked:
                await browser.close()
                return processed_item_count

            # --- å…³é—­å¹¿å‘Šå¼¹çª— ---
            try:
                await page.click("div[class*='closeIconBg']", timeout=3000)
                print("LOG: å·²å…³é—­å¹¿å‘Šå¼¹çª—ã€‚")
            except PlaywrightTimeoutError:
                print("LOG: æœªæ£€æµ‹åˆ°å¹¿å‘Šå¼¹çª—ã€‚")

            # --- æ­¥éª¤ 2: åº”ç”¨ç­›é€‰æ¡ä»¶ ---
            final_response = None
            log_time("æ­¥éª¤ 2 - åº”ç”¨ç­›é€‰æ¡ä»¶...")
            
            # ç‚¹å‡»"æ–°å‘å¸ƒ"ç­›é€‰
