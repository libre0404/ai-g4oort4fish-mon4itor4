import asyncio
import base64
import json
import os
import re
import sys
import shutil
from datetime import datetime
from urllib.parse import urlencode, urlparse, urlunparse, parse_qsl

import requests

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8ï¼Œè§£å†³Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform.startswith('win'):
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

from src.config import (
    AI_DEBUG_MODE,
    IMAGE_SAVE_DIR,
    TASK_IMAGE_DIR_PREFIX,
    MODEL_NAME,
    NTFY_TOPIC_URL,
    GOTIFY_URL,
    GOTIFY_TOKEN,
    BARK_URL,
    PCURL_TO_MOBILE,
    WX_BOT_URL,
    TELEGRAM_BOT_TOKEN,
    TELEGRAM_CHAT_ID,
    WEBHOOK_URL,
    WEBHOOK_METHOD,
    WEBHOOK_HEADERS,
    WEBHOOK_CONTENT_TYPE,
    WEBHOOK_QUERY_PARAMETERS,
    WEBHOOK_BODY,
    ENABLE_RESPONSE_FORMAT,
    client,
    get_image_download_headers,  # æ–°å¢ï¼šåŠ¨æ€è·å–å›¾ç‰‡è¯·æ±‚å¤´
)
from src.utils import convert_goofish_link, retry_on_failure


def safe_print(text):
    """å®‰å…¨çš„æ‰“å°å‡½æ•°ï¼Œå¤„ç†ç¼–ç é”™è¯¯"""
    try:
        print(text)
    except UnicodeEncodeError:
        try:
            print(text.encode('ascii', errors='ignore').decode('ascii'))
        except Exception:
            print("[è¾“å‡ºåŒ…å«æ— æ³•æ˜¾ç¤ºçš„å­—ç¬¦]")


@retry_on_failure(retries=2, delay=3)
async def _download_single_image(url, save_path):
    """ä¸€ä¸ªå¸¦é‡è¯•çš„å†…éƒ¨å‡½æ•°ï¼Œç”¨äºå¼‚æ­¥ä¸‹è½½å•ä¸ªå›¾ç‰‡ã€‚"""
    loop = asyncio.get_running_loop()
    # ä½¿ç”¨ run_in_executor è¿è¡ŒåŒæ­¥çš„ requests ä»£ç ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    response = await loop.run_in_executor(
        None,
        lambda: requests.get(
            url,
            headers=get_image_download_headers(),  # è¿™é‡Œæ”¹æˆæ¯æ¬¡åŠ¨æ€è·å– headers
            timeout=20,
            stream=True,
        ),
    )
    response.raise_for_status()
    with open(save_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)
    return save_path


async def download_all_images(product_id, image_urls, task_name="default"):
    """å¼‚æ­¥ä¸‹è½½ä¸€ä¸ªå•†å“çš„æ‰€æœ‰å›¾ç‰‡ã€‚å¦‚æœå›¾ç‰‡å·²å­˜åœ¨åˆ™è·³è¿‡ã€‚æ”¯æŒä»»åŠ¡éš”ç¦»ã€‚"""
    if not image_urls:
        return []

    task_image_dir = os.path.join(IMAGE_SAVE_DIR, f"{TASK_IMAGE_DIR_PREFIX}{task_name}")
    os.makedirs(task_image_dir, exist_ok=True)

    urls = [url.strip() for url in image_urls if url.strip().startswith('http')]
    if not urls:
        return []

    saved_paths = []
    total_images = len(urls)
    for i, url in enumerate(urls):
        try:
            clean_url = url.split('.heic')[0] if '.heic' in url else url
            file_name_base = os.path.basename(clean_url).split('?')[0]
            file_name = f"product_{product_id}_{i + 1}_{file_name_base}"
            file_name = re.sub(r'[\\/*?:"<>|]', "", file_name)
            if not os.path.splitext(file_name)[1]:
                file_name += ".jpg"

            save_path = os.path.join(task_image_dir, file_name)

            if os.path.exists(save_path):
                safe_print(f"   [å›¾ç‰‡] å›¾ç‰‡ {i + 1}/{total_images} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {os.path.basename(save_path)}")
                saved_paths.append(save_path)
                continue

            safe_print(f"   [å›¾ç‰‡] æ­£åœ¨ä¸‹è½½å›¾ç‰‡ {i + 1}/{total_images}: {url}")
            if await _download_single_image(url, save_path):
                safe_print(f"   [å›¾ç‰‡] å›¾ç‰‡ {i + 1}/{total_images} å·²æˆåŠŸä¸‹è½½åˆ°: {os.path.basename(save_path)}")
                saved_paths.append(save_path)
        except Exception as e:
            safe_print(f"   [å›¾ç‰‡] å¤„ç†å›¾ç‰‡ {url} æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå·²è·³è¿‡æ­¤å›¾: {e}")

    return saved_paths


def cleanup_task_images(task_name):
    """æ¸…ç†æŒ‡å®šä»»åŠ¡çš„å›¾ç‰‡ç›®å½•"""
    task_image_dir = os.path.join(IMAGE_SAVE_DIR, f"{TASK_IMAGE_DIR_PREFIX}{task_name}")
    if os.path.exists(task_image_dir):
        try:
            shutil.rmtree(task_image_dir)
            safe_print(f"   [æ¸…ç†] å·²åˆ é™¤ä»»åŠ¡ '{task_name}' çš„ä¸´æ—¶å›¾ç‰‡ç›®å½•: {task_image_dir}")
        except Exception as e:
            safe_print(f"   [æ¸…ç†] åˆ é™¤ä»»åŠ¡ '{task_name}' çš„ä¸´æ—¶å›¾ç‰‡ç›®å½•æ—¶å‡ºé”™: {e}")
    else:
        safe_print(f"   [æ¸…ç†] ä»»åŠ¡ '{task_name}' çš„ä¸´æ—¶å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {task_image_dir}")


def encode_image_to_base64(image_path):
    """å°†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²ã€‚"""
    if not image_path or not os.path.exists(image_path):
        return None
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        safe_print(f"ç¼–ç å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        return None


def validate_ai_response_format(parsed_response):
    """éªŒè¯AIå“åº”çš„æ ¼å¼æ˜¯å¦ç¬¦åˆé¢„æœŸç»“æ„"""
    required_fields = [
        "prompt_version",
        "is_recommended",
        "reason",
        "risk_tags",
        "criteria_analysis",
    ]

    criteria_analysis_fields = [
        "model_chip",
        "battery_health",
        "condition",
        "history",
        "seller_type",
        "shipping",
        "seller_credit",
    ]

    # æ£€æŸ¥é¡¶å±‚å­—æ®µ
    for field in required_fields:
        if field not in parsed_response:
            safe_print(f"   [AIåˆ†æ] è­¦å‘Šï¼šå“åº”ç¼ºå°‘å¿…éœ€å­—æ®µ '{field}'")
            return False

    criteria_analysis = parsed_response.get("criteria_analysis", {})
    for field in criteria_analysis_fields:
        if field not in criteria_analysis:
            safe_print(f"   [AIåˆ†æ] è­¦å‘Šï¼šcriteria_analysisç¼ºå°‘å­—æ®µ '{field}'")
            return False

    seller_type = criteria_analysis.get("seller_type", {})
    if "analysis_details" in seller_type:
        analysis_details = seller_type["analysis_details"]
        required_details = [
            "temporal_analysis",
            "selling_behavior",
            "buying_behavior",
            "behavioral_summary",
        ]
        for detail in required_details:
            if detail not in analysis_details:
                safe_print(f"   [AIåˆ†æ] è­¦å‘Šï¼šanalysis_detailsç¼ºå°‘å­—æ®µ '{detail}'")
                return False

    if not isinstance(parsed_response.get("is_recommended"), bool):
        safe_print("   [AIåˆ†æ] è­¦å‘Šï¼šis_recommendedå­—æ®µä¸æ˜¯å¸ƒå°”ç±»å‹")
        return False

    if not isinstance(parsed_response.get("risk_tags"), list):
        safe_print("   [AIåˆ†æ] è­¦å‘Šï¼šrisk_tagså­—æ®µä¸æ˜¯åˆ—è¡¨ç±»å‹")
        return False

    return True


@retry_on_failure(retries=3, delay=5)
async def send_ntfy_notification(product_data, reason):
    """å½“å‘ç°æ¨èå•†å“æ—¶ï¼Œå¼‚æ­¥å‘é€ä¸€ä¸ªé«˜ä¼˜å…ˆçº§çš„ ntfy.sh é€šçŸ¥ã€‚"""
    if not NTFY_TOPIC_URL and not WX_BOT_URL and not (GOTIFY_URL and GOTIFY_TOKEN) and not BARK_URL and not (TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID) and not WEBHOOK_URL:
        safe_print("è­¦å‘Šï¼šæœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»»ä½•é€šçŸ¥æœåŠ¡ (NTFY_TOPIC_URL, WX_BOT_URL, GOTIFY_URL/TOKEN, BARK_URL, TELEGRAM_BOT_TOKEN/CHAT_ID, WEBHOOK_URL)ï¼Œè·³è¿‡é€šçŸ¥ã€‚")
        return

    title = product_data.get('å•†å“æ ‡é¢˜', 'N/A')
    price = product_data.get('å½“å‰å”®ä»·', 'N/A')
    link = product_data.get('å•†å“é“¾æ¥', '#')
    if PCURL_TO_MOBILE:
        mobile_link = convert_goofish_link(link)
        message = f"ä»·æ ¼: {price}\nåŸå› : {reason}\næ‰‹æœºç«¯é“¾æ¥: {mobile_link}\nç”µè„‘ç«¯é“¾æ¥: {link}"
    else:
        message = f"ä»·æ ¼: {price}\nåŸå› : {reason}\né“¾æ¥: {link}"

    notification_title = f"ğŸš¨ æ–°æ¨è! {title[:30]}..."

    # ä¸‹é¢çš„é€šçŸ¥é€»è¾‘ä¿æŒä¸å˜â€¦â€¦
    # ï¼ˆntfy / Gotify / Bark / å¾®ä¿¡æœºå™¨äºº / Telegram / Webhook ä»£ç ä¸ä½ åŸæ–‡ä¸€è‡´ï¼‰

    # --- å‘é€ ntfy é€šçŸ¥ ---
    # ... æ­¤å¤„çœç•¥ï¼Œä¸åŸæ–‡ä»¶ç›¸åŒ ...

    # --- å‘é€ Gotify é€šçŸ¥ ---
    # ... ä¸åŸæ–‡ä»¶ç›¸åŒ ...

    # --- å‘é€ Bark é€šçŸ¥ ---
    # ... ä¸åŸæ–‡ä»¶ç›¸åŒ ...

    # --- å‘é€ä¼ä¸šå¾®ä¿¡æœºå™¨äººé€šçŸ¥ ---
    # ... ä¸åŸæ–‡ä»¶ç›¸åŒ ...

    # --- å‘é€ Telegram æœºå™¨äººé€šçŸ¥ ---
    # ... ä¸åŸæ–‡ä»¶ç›¸åŒ ...

    # --- å‘é€é€šç”¨ Webhook é€šçŸ¥ ---
    # ... ä¸åŸæ–‡ä»¶ç›¸åŒ ...


@retry_on_failure(retries=3, delay=5)
async def get_ai_analysis(product_data, image_paths=None, prompt_text=""):
    """å°†å®Œæ•´çš„å•†å“JSONæ•°æ®å’Œæ‰€æœ‰å›¾ç‰‡å‘é€ç»™ AI è¿›è¡Œåˆ†æï¼ˆå¼‚æ­¥ï¼‰ã€‚"""
    if not client:
        safe_print("   [AIåˆ†æ] é”™è¯¯ï¼šAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡åˆ†æã€‚")
        return None

    item_info = product_data.get('å•†å“ä¿¡æ¯', {})
    product_id = item_info.get('å•†å“ID', 'N/A')

    safe_print(f"\n   [AIåˆ†æ] å¼€å§‹åˆ†æå•†å“ #{product_id} (å« {len(image_paths or [])} å¼ å›¾ç‰‡)...")
    safe_print(f"   [AIåˆ†æ] æ ‡é¢˜: {item_info.get('å•†å“æ ‡é¢˜', 'æ— ')}")

    if not prompt_text:
        safe_print("   [AIåˆ†æ] é”™è¯¯ï¼šæœªæä¾›AIåˆ†ææ‰€éœ€çš„promptæ–‡æœ¬ã€‚")
        return None

    product_details_json = json.dumps(product_data, ensure_ascii=False, indent=2)
    system_prompt = prompt_text

    if AI_DEBUG_MODE:
        safe_print("\n--- [AI DEBUG] ---")
        safe_print("--- PRODUCT DATA (JSON) ---")
        safe_print(product_details_json)
        safe_print("--- PROMPT TEXT (å®Œæ•´å†…å®¹) ---")
        safe_print(prompt_text)
        safe_print("-------------------\n")

    combined_text_prompt = f"""è¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†å’Œæˆ‘çš„è¦æ±‚ï¼Œåˆ†æä»¥ä¸‹å®Œæ•´çš„å•†å“JSONæ•°æ®ï¼š

```json
    {product_details_json}
```

{system_prompt}
"""
    user_content_list = []

    # å…ˆæ·»åŠ å›¾ç‰‡å†…å®¹
    if image_paths:
        for path in image_paths:
            base64_image = encode_image_to_base64(path)
            if base64_image:
                user_content_list.append(
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}})

    # å†æ·»åŠ æ–‡æœ¬å†…å®¹
    user_content_list.append({"type": "text", "text": combined_text_prompt})

    messages = [{"role": "user", "content": user_content_list}]

    # ä¿å­˜æœ€ç»ˆä¼ è¾“å†…å®¹åˆ°æ—¥å¿—æ–‡ä»¶
    try:
        # åˆ›å»ºlogsæ–‡ä»¶å¤¹
        logs_dir = "logs"
        os.makedirs(logs_dir, exist_ok=True)

        # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶åï¼ˆå½“å‰æ—¶é—´ï¼‰
        current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"{current_time}.log"
        log_filepath = os.path.join(logs_dir, log_filename)

        # å‡†å¤‡æ—¥å¿—å†…å®¹ - ç›´æ¥ä¿å­˜åŸå§‹ä¼ è¾“å†…å®¹
        log_content = json.dumps(messages, ensure_ascii=False)

        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        with open(log_filepath, 'w', encoding='utf-8') as f:
            f.write(log_content)

        safe_print(f"   [æ—¥å¿—] AIåˆ†æè¯·æ±‚å·²ä¿å­˜åˆ°: {log_filepath}")

    except Exception as e:
        safe_print(f"   [æ—¥å¿—] ä¿å­˜AIåˆ†ææ—¥å¿—æ—¶å‡ºé”™: {e}")

    # å¢å¼ºçš„AIè°ƒç”¨ï¼ŒåŒ…å«æ›´ä¸¥æ ¼çš„æ ¼å¼æ§åˆ¶å’Œé‡è¯•æœºåˆ¶
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # æ ¹æ®é‡è¯•æ¬¡æ•°è°ƒæ•´å‚æ•°
            current_temperature = 0.1 if attempt == 0 else 0.05  # é‡è¯•æ—¶ä½¿ç”¨æ›´ä½çš„æ¸©åº¦

            from src.config import get_ai_request_params
            
            # æ„å»ºè¯·æ±‚å‚æ•°ï¼Œæ ¹æ®ENABLE_RESPONSE_FORMATå†³å®šæ˜¯å¦ä½¿ç”¨response_format
            request_params = {
                "model": MODEL_NAME,
                "messages": messages,
                "temperature": current_temperature,
                "max_tokens": 4000
            }
            
            # åªæœ‰å¯ç”¨response_formatæ—¶æ‰æ·»åŠ è¯¥å‚æ•°
            if ENABLE_RESPONSE_FORMAT:
                request_params["response_format"] = {"type": "json_object"}
            
            response = await client.chat.completions.create(
                **get_ai_request_params(**request_params)
            )

            ai_response_content = response.choices[0].message.content

            if AI_DEBUG_MODE:
                safe_print(f"\n--- [AI DEBUG] ç¬¬{attempt + 1}æ¬¡å°è¯• ---")
                safe_print("--- RAW AI RESPONSE ---")
                safe_print(ai_response_content)
                safe_print("---------------------\n")

            # å°è¯•ç›´æ¥è§£æJSON
            try:
                parsed_response = json.loads(ai_response_content)

                # éªŒè¯å“åº”æ ¼å¼
                if validate_ai_response_format(parsed_response):
                    safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•æˆåŠŸï¼Œå“åº”æ ¼å¼éªŒè¯é€šè¿‡")
                    return parsed_response
                else:
                    safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•æ ¼å¼éªŒè¯å¤±è´¥")
                    if attempt < max_retries - 1:
                        safe_print(f"   [AIåˆ†æ] å‡†å¤‡ç¬¬{attempt + 2}æ¬¡é‡è¯•...")
                        continue
                    else:
                        safe_print("   [AIåˆ†æ] æ‰€æœ‰é‡è¯•å®Œæˆï¼Œä½¿ç”¨æœ€åä¸€æ¬¡ç»“æœ")
                        return parsed_response

            except json.JSONDecodeError:
                safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•JSONè§£æå¤±è´¥ï¼Œå°è¯•æ¸…ç†å“åº”å†…å®¹...")

                # æ¸…ç†å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
                cleaned_content = ai_response_content.strip()
                if cleaned_content.startswith('```json'):
                    cleaned_content = cleaned_content[7:]
                if cleaned_content.startswith('```'):
                    cleaned_content = cleaned_content[3:]
                if cleaned_content.endswith('```'):
                    cleaned_content = cleaned_content[:-3]
                cleaned_content = cleaned_content.strip()

                # å¯»æ‰¾JSONå¯¹è±¡è¾¹ç•Œ
                json_start_index = cleaned_content.find('{')
                json_end_index = cleaned_content.rfind('}')

                if json_start_index != -1 and json_end_index != -1 and json_end_index > json_start_index:
                    json_str = cleaned_content[json_start_index:json_end_index + 1]
                    try:
                        parsed_response = json.loads(json_str)
                        if validate_ai_response_format(parsed_response):
                            safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•æ¸…ç†åæˆåŠŸ")
                            return parsed_response
                        else:
                            if attempt < max_retries - 1:
                                safe_print(f"   [AIåˆ†æ] å‡†å¤‡ç¬¬{attempt + 2}æ¬¡é‡è¯•...")
                                continue
                            else:
                                safe_print("   [AIåˆ†æ] æ‰€æœ‰é‡è¯•å®Œæˆï¼Œä½¿ç”¨æ¸…ç†åçš„ç»“æœ")
                                return parsed_response
                    except json.JSONDecodeError as e:
                        safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•æ¸…ç†åJSONè§£æä»ç„¶å¤±è´¥: {e}")
                        if attempt < max_retries - 1:
                            safe_print(f"   [AIåˆ†æ] å‡†å¤‡ç¬¬{attempt + 2}æ¬¡é‡è¯•...")
                            continue
                        else:
                            raise e
                else:
                    safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•æ— æ³•åœ¨å“åº”ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„JSONå¯¹è±¡")
                    if attempt < max_retries - 1:
                        safe_print(f"   [AIåˆ†æ] å‡†å¤‡ç¬¬{attempt + 2}æ¬¡é‡è¯•...")
                        continue
                    else:
                        raise json.JSONDecodeError("No valid JSON object found", ai_response_content, 0)

        except Exception as e:
            safe_print(f"   [AIåˆ†æ] ç¬¬{attempt + 1}æ¬¡å°è¯•AIè°ƒç”¨å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                safe_print(f"   [AIåˆ†æ] å‡†å¤‡ç¬¬{attempt + 2}æ¬¡é‡è¯•...")
                continue
            else:
                raise e
